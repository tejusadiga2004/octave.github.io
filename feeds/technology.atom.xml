<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Entropy Pages - Technology</title><link href="https://blogs.entropypages.in/" rel="alternate"/><link href="https://blogs.entropypages.in/feeds/technology.atom.xml" rel="self"/><id>https://blogs.entropypages.in/</id><updated>2025-08-02T13:24:00+05:30</updated><entry><title>Apple Foundation Models: The Power of Structured Data</title><link href="https://blogs.entropypages.in/apple-foundation-models-structured-data.html" rel="alternate"/><published>2025-08-02T13:24:00+05:30</published><updated>2025-08-02T13:24:00+05:30</updated><author><name>Tejus Adiga M</name></author><id>tag:blogs.entropypages.in,2025-08-02:/apple-foundation-models-structured-data.html</id><summary type="html">&lt;p&gt;An expert's guide to Apple's foundation models, focusing on the importance of structured input/output, comparing on-device and server models, and providing a Swift example.&lt;/p&gt;</summary><content type="html">&lt;h1 id="apple-foundation-models-the-power-of-structured-data"&gt;Apple Foundation Models: The Power of Structured Data&lt;/h1&gt;
&lt;p&gt;Apple's foray into foundation models marks an exciting development, bringing sophisticated machine learning capabilities closer to the user than ever before. A key aspect of these models is their emphasis on &lt;strong&gt;structured input and output&lt;/strong&gt;. This blog post will delve into why this structured approach is crucial, how it can be implemented in various programming languages, compare on-device and server-grade model capabilities, and explore the practical applications of on-device models on Apple platforms with a Swift example.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="the-necessity-of-structured-input-and-output"&gt;The Necessity of Structured Input and Output&lt;/h3&gt;
&lt;p&gt;In the realm of machine learning, the way data is fed into a model and how the results are presented significantly impacts the model's performance, interpretability, and usability. For foundation models, which are designed to be versatile and adaptable to a wide range of tasks, structured input and output are particularly vital for several reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clarity and Consistency:&lt;/strong&gt; Structured formats like JSON, Protocol Buffers, or even well-defined data classes provide a clear and consistent way to represent information. This eliminates ambiguity and ensures that the model and the applications interacting with it understand the data in the same way.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Facilitating Downstream Tasks:&lt;/strong&gt; When a model outputs structured data, it becomes significantly easier for other parts of an application or other models to consume and process this information. For instance, if an on-device model identifies objects in an image and outputs the results as a JSON array with bounding boxes and labels, a subsequent module can directly use this structured data to display annotations on the image or perform further analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Improved Model Training and Fine-tuning:&lt;/strong&gt; Training data that is consistently structured helps the model learn patterns and relationships more effectively. Similarly, when fine-tuning a pre-trained foundation model for a specific task, providing structured input and defining the expected structured output allows for more targeted learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interoperability:&lt;/strong&gt; Structured data formats are often language-agnostic, making it easier to integrate models and applications written in different programming languages.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="designing-structured-input-and-output-in-other-languages"&gt;Designing Structured Input and Output in Other Languages&lt;/h3&gt;
&lt;p&gt;The principles of structured input and output are not unique to Apple's ecosystem and can be implemented effectively in various programming languages. The key is to choose appropriate data structures and serialization/deserialization methods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt; Python, with its rich ecosystem, offers several ways to handle structured data. Dictionaries and lists can be naturally used to represent structured information. Libraries like &lt;code&gt;json&lt;/code&gt; for JSON serialization, &lt;code&gt;pickle&lt;/code&gt; for Python-specific serialization, and &lt;code&gt;protobuf&lt;/code&gt; for Protocol Buffers provide robust mechanisms for encoding and decoding structured data. Data classes (introduced in Python 3.7) offer a concise way to define classes that primarily store data, making them ideal for representing structured inputs and outputs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Java:&lt;/strong&gt; Java, being a strongly-typed language, encourages the creation of classes to represent data structures. Libraries like &lt;code&gt;Gson&lt;/code&gt; and &lt;code&gt;Jackson&lt;/code&gt; are widely used for JSON serialization and deserialization. Protocol Buffers also have excellent support in Java.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;JavaScript:&lt;/strong&gt; JavaScript, being the language of the web, naturally works well with JSON. Objects and arrays are fundamental data structures for representing structured information.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In essence, regardless of the programming language, the process involves:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Defining a Schema:&lt;/strong&gt; Clearly define the structure of the input and output data, including the data types and relationships between different fields.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Using Data Structures:&lt;/strong&gt; Utilize the language's built-in or library-provided data structures (like dictionaries, lists, objects, classes) to represent the structured data according to the defined schema.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Serialization and Deserialization:&lt;/strong&gt; Employ appropriate libraries or built-in functions to convert between the in-memory data structures and a standardized format (like JSON or Protocol Buffers) for inputting to and outputting from the model.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id="on-device-vs-server-grade-models-capabilities-and-applications"&gt;On-Device vs. Server-Grade Models: Capabilities and Applications&lt;/h3&gt;
&lt;p&gt;Apple's focus on on-device foundation models presents a compelling alternative to relying solely on server-based models. Both approaches have their own strengths and are suitable for different applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Server-Grade Models:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capabilities:&lt;/strong&gt; Server-grade models, benefiting from vast computational resources and massive datasets, typically boast higher accuracy and the ability to handle more complex tasks. They can power sophisticated natural language processing, large-scale image and video analysis, and intricate predictive analytics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Applications:&lt;/strong&gt; These models are well-suited for tasks that require high precision, complex reasoning, and access to extensive knowledge, such as:&lt;ul&gt;
&lt;li&gt;Cloud-based search engines&lt;/li&gt;
&lt;li&gt;Large language model powered chatbots&lt;/li&gt;
&lt;li&gt;Complex video editing and analysis platforms&lt;/li&gt;
&lt;li&gt;Training and fine-tuning of large foundation models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;On-Device Models:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capabilities:&lt;/strong&gt; On-device models are designed to be efficient and performant on resource-constrained devices like iPhones, iPads, and Macs. While they might have lower overall capacity compared to their server counterparts, they offer several key advantages:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Privacy:&lt;/strong&gt; Data processed by on-device models stays on the user's device, enhancing privacy and security.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latency:&lt;/strong&gt; Eliminating the need for network communication results in significantly lower latency, leading to a more responsive user experience.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Connectivity Independence:&lt;/strong&gt; On-device models can function even without an internet connection.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost Efficiency:&lt;/strong&gt; Offloading computation to the device reduces the processing load and associated costs on remote servers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Applications:&lt;/strong&gt; On-device foundation models are ideal for tasks that benefit from privacy, low latency, and offline functionality, such as:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Real-time language translation:&lt;/strong&gt; Translating spoken or written text instantly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Image and object recognition:&lt;/strong&gt; Identifying objects and scenes in photos and videos locally.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Personalized recommendations:&lt;/strong&gt; Providing tailored suggestions based on user behavior without sending data to a server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enhanced accessibility features:&lt;/strong&gt; Enabling real-time transcription or object detection for visually impaired users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context-aware suggestions:&lt;/strong&gt; Providing relevant suggestions based on the current on-device context.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id="tasks-achievable-with-on-device-models-on-apple-platforms-a-swift-example"&gt;Tasks Achievable with On-Device Models on Apple Platforms: A Swift Example&lt;/h3&gt;
&lt;p&gt;Apple's Core ML framework provides the infrastructure to integrate machine learning models, including foundation models, seamlessly into iOS, iPadOS, and macOS applications. Here's a simplified example in Swift demonstrating how an on-device model could perform object recognition and output structured data:&lt;/p&gt;
&lt;p&gt;First, assume you have a Core ML model (&lt;code&gt;ObjectDetector.mlmodel&lt;/code&gt;) that takes an image as input and outputs a dictionary containing an array of detected objects. Each object in the array is another dictionary with keys like &lt;code&gt;"label"&lt;/code&gt; (String) and &lt;code&gt;"boundingBox"&lt;/code&gt; (VNRectangle).&lt;/p&gt;
&lt;p&gt;Here's how you might use this model in Swift:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kd"&gt;import&lt;/span&gt; &lt;span class="nc"&gt;CoreML&lt;/span&gt;
&lt;span class="kd"&gt;import&lt;/span&gt; &lt;span class="nc"&gt;Vision&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt; &lt;span class="nf"&gt;detectObjects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;CIImage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;completion&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="n"&gt;escaping&lt;/span&gt; &lt;span class="p"&gt;([(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;boundingBox&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;CGRect&lt;/span&gt;&lt;span class="p"&gt;)]?)&lt;/span&gt; &lt;span class="p"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;Void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;guard&lt;/span&gt; &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;?&lt;/span&gt; &lt;span class="bp"&gt;VNCoreMLModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ObjectDetector&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="bp"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Failed to load Core ML model.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;completion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;request&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;VNCoreMLRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt;
        &lt;span class="k"&gt;guard&lt;/span&gt; &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;results&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="p"&gt;?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;VNRecognizedObjectObservation&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt; &lt;span class="p"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;nil&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="bp"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Object detection error: &lt;/span&gt;&lt;span class="si"&gt;\(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;?.&lt;/span&gt;&lt;span class="n"&gt;localizedDescription&lt;/span&gt; &lt;span class="p"&gt;??&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Unknown error&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;completion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;detectedObjects&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="bp"&gt;map&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;observation&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt;
            &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;label&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;observation&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="bp"&gt;first&lt;/span&gt;&lt;span class="p"&gt;?.&lt;/span&gt;&lt;span class="n"&gt;identifier&lt;/span&gt; &lt;span class="p"&gt;??&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Unknown&amp;quot;&lt;/span&gt;
            &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;boundingBox&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;observation&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundingBox&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;boundingBox&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;boundingBox&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;completion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;detectedObjects&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;handler&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;VNImageRequestHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ciImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="n"&gt;handler&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;perform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="bp"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error performing image request: &lt;/span&gt;&lt;span class="si"&gt;\(&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;localizedDescription&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;completion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;nil&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// Example usage:&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;image&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;CIImage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;contentsOf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fileURLWithPath&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;path/to/your/image.jpg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;detectObjects&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;detectedObjects&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;detectedObjects&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;object&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;objects&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="bp"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Detected: &lt;/span&gt;&lt;span class="si"&gt;\(&lt;/span&gt;&lt;span class="n"&gt;object&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;&lt;span class="s"&gt; at &lt;/span&gt;&lt;span class="si"&gt;\(&lt;/span&gt;&lt;span class="n"&gt;object&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boundingBox&lt;/span&gt;&lt;span class="si"&gt;)&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="c1"&gt;// Further processing of the structured output (e.g., displaying on screen)&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="bp"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;No objects detected or an error occurred.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this example, the detectObjects function takes a CIImage as input and uses a Core ML model to perform object detection. The completion handler receives an optional array of tuples, where each tuple represents a detected object and contains its label (String) and bounding box (CGRect) â€“ a structured output. This structured data can then be easily used by other parts of the application to draw bounding boxes on the image, display labels, or trigger other actions based on the detected objects.
Conclusion
Structured input and output are fundamental to the effective use of foundation models, especially in resource-constrained environments like on-device applications. By adhering to well-defined data formats, developers can build robust, interoperable, and efficient applications that leverage the power of machine learning while prioritizing user privacy and experience. Apple's commitment to on-device models, coupled with the capabilities of Core ML, opens up a world of possibilities for innovative and intelligent features directly on Apple platforms.&lt;/p&gt;</content><category term="Technology"/><category term="machine-learning"/><category term="apple"/><category term="on-device-ml"/><category term="foundation-models"/></entry></feed>